# ğŸ§  **AnÃ¡lise de Attrition de FuncionÃ¡rios â€” SoluÃ§Ã£o de BI & Machine Learning**
Projeto de anÃ¡lise e prediÃ§Ã£o de rotatividade de funcionÃ¡rios. A soluÃ§Ã£o evolui de um pipeline de Machine Learning para uma arquitetura completa de Business Intelligence + ML, com camadas estratÃ©gicas (Power BI), tÃ¡ticas (Streamlit) e operacionais (API REST) para apoiar decisÃµes no setor de RH.

---

## ğŸ›ï¸ **Arquitetura da SoluÃ§Ã£o**

**Banco de Dados Central:**
- PostgreSQL â†’ Armazena dados dos funcionÃ¡rios, logs de prediÃ§Ãµes da API e serve como fonte para as camadas tÃ¡tica e estratÃ©gica.

### **Camadas:**
- **EstratÃ©gica (Power BI):** Dashboards e KPIs de turnover para alta gestÃ£o.
- **TÃ¡tica (Streamlit):** Dashboard de diagnÃ³stico individual e ranking de risco para gestores e RH.
- **Operacional (API REST):** ServiÃ§o automatizado de prediÃ§Ã£o para outros sistemas, com deploy na nuvem.

---

------------------------------------
ğŸ“‚ ESTRUTURA DO PROJETO
------------------------------------

```
.
â”œâ”€â”€ ğŸ“ .github/
â”œâ”€â”€ ğŸ“ .pytest_cache/
â”œâ”€â”€ ğŸ“ .venv/
â”œâ”€â”€ ğŸ“ api/
â”œâ”€â”€ ğŸ“ app/
â”œâ”€â”€ ğŸ“ artifacts/
â”œâ”€â”€ ğŸ“ attrition.egg-info/
â”œâ”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“ database/
â”œâ”€â”€ ğŸ“ htmlcov/
â”œâ”€â”€ ğŸ“ models/
â”œâ”€â”€ ğŸ“ notebooks/
â”œâ”€â”€ ğŸ“ reports/
â”œâ”€â”€ ğŸ“ scripts/
â”œâ”€â”€ ğŸ“ sql/
â”œâ”€â”€ ğŸ“ src/
â”œâ”€â”€ ğŸ“ tests/
â”œâ”€â”€ ğŸ“„ .coverage
â”œâ”€â”€ ğŸ“„ .dockerignore
â”œâ”€â”€ ğŸ“„ .env
â”œâ”€â”€ ğŸ“„ .env.example
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ .pre-commit-config.yaml
â”œâ”€â”€ ğŸ“„ Dockerfile
â”œâ”€â”€ ğŸ“„ LICENSE
â”œâ”€â”€ ğŸ“„ Makefile
â”œâ”€â”€ ğŸ“„ poetry.lock
â”œâ”€â”€ ğŸ“„ pyproject.toml
â”œâ”€â”€ ğŸ“„ README.md
â””â”€â”€ ğŸ“„ setup.cfg
```

## âš™ï¸ **Stack TecnolÃ³gica**

### **Dados & BI**
- PostgreSQL, SQLAlchemy, Power BI

**Modelagem & Core**
- Python 3.10+, Pandas, NumPy
- Scikit-learn, XGBoost, Optuna, Imbalanced-learn

**VisualizaÃ§Ã£o & Apps**
- Streamlit, SHAP, Matplotlib, Seaborn, FastAPI

**Dev & MLOps**
- Poetry, python-dotenv, Git, Docker, Render
- Pytest, Pre-commit, Black, isort, Flake8

---

## ğŸš€ **Como Rodar o Projeto (Localmente)**

1. **PrÃ©-requisitos:**
   - Python 3.10+
   - Poetry e Git

2. **InstalaÃ§Ã£o e ConfiguraÃ§Ã£o:**

```bash
# Clone o repositÃ³rio
git clone https://github.com/Tentorias/employee-attrition-analysis.git
cd employee-attrition-analysis

# Instale as dependÃªncias
poetry install

# Crie e configure o arquivo de ambiente
cp .env.example .env
```

- ApÃ³s o Ãºltimo comando, edite o arquivo `.env` e preencha a `DATABASE_URL` com a URL do seu banco PostgreSQL.

3. **ExecuÃ§Ã£o do Pipeline e AplicaÃ§Ãµes:**

**a. Popule a Base de Dados**

```bash
# Carrega os dados do CSV para o PostgreSQL (execute apenas uma vez)
poetry run python scripts/migrate_to_postgres.py
```

**b. Execute o Pipeline de ML Completo**

```bash
# O argumento --tune ativa a otimizaÃ§Ã£o de hiperparÃ¢metros para maximizar o recall
poetry run python src/attrition/main.py run-pipeline --tune
```

**c. Popule o Dashboard com as PrediÃ§Ãµes**

```bash
# Usa a API local para gerar e salvar as prediÃ§Ãµes de toda a base no banco de dados
poetry run python scripts/run_batch_predictions.py
```

**d. Inicie as AplicaÃ§Ãµes**

```bash
# Inicia o dashboard tÃ¡tico
poetry run streamlit run app/main_app.py

# Inicia a API operacional localmente
poetry run uvicorn api.main:app --reload
```

---

## ğŸ”— **Pipeline de Machine Learning (Ã€ Prova de Data Leakage)**

- **DivisÃ£o de Dados Primeiro:** O dataset bruto Ã© imediatamente dividido em conjuntos de treino e teste.
- **PrÃ©-processamento Separado:** Todas as etapas que "aprendem" com os dados (encoding de categorias, etc.) sÃ£o treinadas apenas no conjunto de treino e depois aplicadas ao conjunto de teste.
- **OtimizaÃ§Ã£o com Optuna:** Os hiperparÃ¢metros do XGBoost sÃ£o otimizados com foco em maximizar o Recall, utilizando o parÃ¢metro `scale_pos_weight` para lidar com o desbalanceamento de classes.
- **CalibraÃ§Ã£o de Threshold:** ApÃ³s o treino, um threshold de decisÃ£o Ã³timo Ã© calculado para encontrar o melhor equilÃ­brio entre Recall e Precision, de acordo com a estratÃ©gia de negÃ³cio.
- **Modelagem e Explicabilidade:** O modelo `XGBClassifier` treinado Ã© salvo, e o SHAP Ã© usado para garantir a explicabilidade das prediÃ§Ãµes.

---

## ğŸ“Š **Resultados do Modelo (Otimizado para F1-Score com PrecisÃ£o MÃ­nima)**

O modelo final foi calibrado para maximizar o F1-score da classe 'Sai', garantindo uma Precision mÃ­nima de 60%.

| MÃ©trica          | Modelo Calibrado (Prod) |
|------------------|-------------------------|
| Precision (Sai)  | 0.61 (61%)              |
| Recall (Sai)     | 0.43 (43%)              |
| F1-Score (Sai)   | 0.50 (50%)              |

### **InterpretaÃ§Ã£o dos Resultados:**

- **Precision de 61%:** De cada 10 funcionÃ¡rios sinalizados como risco de saÃ­da pelo modelo, aproximadamente 6 sÃ£o de fato casos de risco real. Isso garante que as aÃ§Ãµes do RH sejam focadas e eficientes, minimizando intervenÃ§Ãµes desnecessÃ¡rias.
- **Recall de 43%:** O modelo consegue identificar corretamente 4 em cada 10 funcionÃ¡rios que de fato sairiam. Isso representa um trade-off: para alcanÃ§ar a alta precisÃ£o desejada (61%), o modelo se tornou mais seletivo e, consequentemente, identifica uma menor parcela dos casos reais de saÃ­da.
- **F1-Score de 50%:** Este valor reflete o balanÃ§o entre Precision e Recall. Embora a Precision seja forte, o Recall ainda apresenta espaÃ§o para melhoria. Isso indica que, dada a restriÃ§Ã£o de Precision, o modelo busca um balanÃ§o aceitÃ¡vel, mas hÃ¡ um caminho para explorar a detecÃ§Ã£o de mais casos de saÃ­da.


