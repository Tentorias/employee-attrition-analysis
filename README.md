ğŸ§  **AnÃ¡lise de Attrition de FuncionÃ¡rios â€” SoluÃ§Ã£o de BI & Machine Learning**
Projeto de anÃ¡lise e prediÃ§Ã£o de rotatividade de funcionÃ¡rios. A soluÃ§Ã£o evolui de um pipeline de Machine Learning para uma arquitetura completa de Business Intelligence + ML, com camadas estratÃ©gicas (Power BI), tÃ¡ticas (Streamlit) e operacionais (API REST) para apoiar decisÃµes no setor de RH.

---

ğŸ›ï¸ **Arquitetura da SoluÃ§Ã£o**

**Banco de Dados Central:**
- PostgreSQL â†’ Armazena dados dos funcionÃ¡rios, logs de prediÃ§Ãµes da API e serve como fonte para as camadas tÃ¡tica e estratÃ©gica.

**Camadas:**
- **EstratÃ©gica (Power BI):** Dashboards e KPIs de turnover para alta gestÃ£o.
- **TÃ¡tica (Streamlit):** Dashboard de diagnÃ³stico individual e ranking de risco para gestores e RH.
- **Operacional (API REST):** ServiÃ§o automatizado de prediÃ§Ã£o para outros sistemas, com deploy na nuvem.

---

''''

------------------------------------
ğŸ“‚ ESTRUTURA DO PROJETO
------------------------------------
.
â”œâ”€â”€ ğŸ“ .github/
â”œâ”€â”€ ğŸ“ .pytest_cache/
â”œâ”€â”€ ğŸ“ .venv/
â”œâ”€â”€ ğŸ“ api/
â”œâ”€â”€ ğŸ“ app/
â”œâ”€â”€ ğŸ“ artifacts/
â”œâ”€â”€ ğŸ“ attrition.egg-info/
â”œâ”€â”€ ğŸ“ data/
â”œâ”€â”€ ğŸ“ database/
â”œâ”€â”€ ğŸ“ htmlcov/
â”œâ”€â”€ ğŸ“ models/
â”œâ”€â”€ ğŸ“ notebooks/
â”œâ”€â”€ ğŸ“ reports/
â”œâ”€â”€ ğŸ“ scripts/
â”œâ”€â”€ ğŸ“ sql/
â”œâ”€â”€ ğŸ“ src/
â”œâ”€â”€ ğŸ“ tests/
â”œâ”€â”€ ğŸ“„ .coverage
â”œâ”€â”€ ğŸ“„ .dockerignore
â”œâ”€â”€ ğŸ“„ .env
â”œâ”€â”€ ğŸ“„ .env.example
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ .pre-commit-config.yaml
â”œâ”€â”€ ğŸ“„ Dockerfile
â”œâ”€â”€ ğŸ“„ LICENSE
â”œâ”€â”€ ğŸ“„ Makefile
â”œâ”€â”€ ğŸ“„ poetry.lock
â”œâ”€â”€ ğŸ“„ pyproject.toml
â”œâ”€â”€ ğŸ“„ README.md
â””â”€â”€ ğŸ“„ setup.cfg

'''''

âš™ï¸ **Stack TecnolÃ³gica**

**Dados & BI**
- PostgreSQL, SQLAlchemy, Power BI

**Modelagem & Core**
- Python 3.10+, Pandas, NumPy
- Scikit-learn, XGBoost, Optuna, Imbalanced-learn

**VisualizaÃ§Ã£o & Apps**
- Streamlit, SHAP, Matplotlib, Seaborn, FastAPI

**Dev & MLOps**
- Poetry, python-dotenv, Git, Docker, Render
- Pytest, Pre-commit, Black, isort, Flake8

---

ğŸš€ **Como Rodar o Projeto (Localmente)**

1. **PrÃ©-requisitos:**
   - Python 3.10+
   - Poetry e Git

2. **InstalaÃ§Ã£o e ConfiguraÃ§Ã£o:**

```bash
# Clone o repositÃ³rio
git clone https://github.com/Tentorias/employee-attrition-analysis.git
cd employee-attrition-analysis

# Instale as dependÃªncias
poetry install

# Crie e configure o arquivo de ambiente
cp .env.example .env
```

- ApÃ³s o Ãºltimo comando, edite o arquivo `.env` e preencha a `DATABASE_URL` com a URL do seu banco PostgreSQL.

3. **ExecuÃ§Ã£o do Pipeline e AplicaÃ§Ãµes:**

**a. Popule a Base de Dados**

```bash
# Carrega os dados do CSV para o PostgreSQL (execute apenas uma vez)
poetry run python scripts/migrate_to_postgres.py
```

**b. Execute o Pipeline de ML Completo**

```bash
# O argumento --tune ativa a otimizaÃ§Ã£o de hiperparÃ¢metros para maximizar o recall
poetry run python src/attrition/main.py run-pipeline --tune
```

**c. Popule o Dashboard com as PrediÃ§Ãµes**

```bash
# Usa a API local para gerar e salvar as prediÃ§Ãµes de toda a base no banco de dados
poetry run python scripts/run_batch_predictions.py
```

**d. Inicie as AplicaÃ§Ãµes**

```bash
# Inicia o dashboard tÃ¡tico
poetry run streamlit run app/main_app.py

# Inicia a API operacional localmente
poetry run uvicorn api.main:app --reload
```

---

ğŸ”— **Pipeline de Machine Learning (Ã€ Prova de Data Leakage)**

- **DivisÃ£o de Dados Primeiro:** O dataset bruto Ã© imediatamente dividido em conjuntos de treino e teste.
- **PrÃ©-processamento Separado:** Todas as etapas que "aprendem" com os dados (encoding de categorias, etc.) sÃ£o treinadas apenas no conjunto de treino e depois aplicadas ao conjunto de teste.
- **OtimizaÃ§Ã£o com Optuna:** Os hiperparÃ¢metros do XGBoost sÃ£o otimizados com foco em maximizar o Recall, utilizando o parÃ¢metro `scale_pos_weight` para lidar com o desbalanceamento de classes.
- **CalibraÃ§Ã£o de Threshold:** ApÃ³s o treino, um threshold de decisÃ£o Ã³timo Ã© calculado para encontrar o melhor equilÃ­brio entre Recall e Precision, de acordo com a estratÃ©gia de negÃ³cio.
- **Modelagem e Explicabilidade:** O modelo `XGBClassifier` treinado Ã© salvo, e o SHAP Ã© usado para garantir a explicabilidade das prediÃ§Ãµes.

---

ğŸ“Š **Resultados do Modelo (Otimizado para Recall)**

O modelo final foi calibrado para atender Ã  necessidade de negÃ³cio de minimizar a perda de talentos, priorizando um alto Recall.

| MÃ©trica            | Modelo Otimizado (Prod) |
|--------------------|--------------------------|
| Precision (Yes)    | 0.41 (41%)               |
| Recall (Yes)       | 0.74 (74%)               |
| F1-Score (Yes)     | 0.53 (53%)               |

**Exportar para as Planilhas:**

- **Recall de 74%:** O modelo consegue identificar corretamente 3 em cada 4 funcionÃ¡rios que de fato sairiam. Essa Ã© a mÃ©trica mais importante para a estratÃ©gia de retenÃ§Ã£o.
- **Precision de 41%:** De cada 10 funcionÃ¡rios sinalizados como risco, aproximadamente 4 sÃ£o casos de risco real, permitindo que a aÃ§Ã£o do RH seja focada e eficiente.
