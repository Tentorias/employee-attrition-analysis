ğŸ§  AnÃ¡lise de Attrition de FuncionÃ¡rios â€” SoluÃ§Ã£o de BI & Machine Learning
Projeto de anÃ¡lise e prediÃ§Ã£o de rotatividade de funcionÃ¡rios. A soluÃ§Ã£o evolui de um pipeline de Machine Learning para uma arquitetura completa de Business Intelligence + ML, com camadas estratÃ©gicas (Power BI), tÃ¡ticas (Streamlit) e operacionais (API REST) para apoiar decisÃµes no setor de RH.

ğŸš€ API de PrediÃ§Ã£o (Deploy PÃºblico)
A API de prediÃ§Ã£o estÃ¡ disponÃ­vel para testes:

DocumentaÃ§Ã£o: https://employee-attrition-analysis.onrender.com/docs

âš ï¸ AtenÃ§Ã£o: A API usa o plano gratuito da Render e pode levar atÃ© 60 segundos para responder Ã  primeira requisiÃ§Ã£o apÃ³s inatividade.

Exemplo de requisiÃ§Ã£o:

curl -X 'POST'   'https://employee-attrition-analysis.onrender.com/predict'   -H 'accept: application/json'   -H 'Content-Type: application/json'   -d '{ ... }'

ğŸ›ï¸ Arquitetura da SoluÃ§Ã£o
Banco de Dados Central: PostgreSQL â†’ Armazena dados dos funcionÃ¡rios, logs de prediÃ§Ãµes da API e serve como fonte para as camadas tÃ¡tica e estratÃ©gica.

Camadas:
EstratÃ©gica (Power BI): Dashboards e KPIs de turnover para alta gestÃ£o, conectados diretamente ao PostgreSQL.

TÃ¡tica (Streamlit): DiagnÃ³stico individual com prediÃ§Ãµes em tempo real e ranking de risco para gestores e RH.

Operacional (API REST): ServiÃ§o automatizado de prediÃ§Ã£o para outros sistemas, com logging integrado ao banco de dados.

âš™ï¸ Stack TecnolÃ³gica
Dados & BI
PostgreSQL, SQLAlchemy, SQL, Power BI

Modelagem & Core
Python 3.10+
Pandas, NumPy
Scikit-learn, LightGBM, XGBoost
SMOTEENN, Optuna

VisualizaÃ§Ã£o & Apps
Streamlit, SHAP, Matplotlib, Seaborn, Jupyter Notebook, FastAPI

Dev & MLOps
Poetry, Git, Git LFS
python-dotenv
Docker, Render
GitHub Actions, Pre-commit, Black, isort, Flake8, Pytest

ğŸ“ Estrutura do Projeto
employee-attrition-analysis/
â”œâ”€â”€ api/                   # API REST (FastAPI)
â”œâ”€â”€ app/                   # App de diagnÃ³stico (Streamlit)
â”œâ”€â”€ artifacts/             # Modelos, features e explicadores
â”œâ”€â”€ data/                  # Dados brutos
â”œâ”€â”€ models/                # Modelos finais de produÃ§Ã£o
â”œâ”€â”€ notebooks/             # EDA e exploraÃ§Ãµes
â”œâ”€â”€ reports/               # Dashboards Power BI
â”œâ”€â”€ scripts/               # Scripts de suporte (ex: migraÃ§Ã£o de dados)
â”œâ”€â”€ sql/                   # Queries SQL para a camada de BI
â”œâ”€â”€ src/                   # Pipeline principal de ML
â”œâ”€â”€ tests/                 # Testes automatizados
â”œâ”€â”€ .env.example           # Molde para variÃ¡veis de ambiente
â”œâ”€â”€ .gitignore             
â”œâ”€â”€ Dockerfile             
â”œâ”€â”€ pyproject.toml         
â””â”€â”€ README.md

ğŸš€ Guia de Uso (Local)
PrÃ©-requisitos:
Python 3.10+
Poetry
Git + Git LFS
Cliente PostgreSQL (psql) instalado e no PATH do sistema.

1. InstalaÃ§Ã£o:
git clone https://github.com/Tentorias/employee-attrition-analysis.git
cd employee-attrition-analysis
poetry install

2. ConfiguraÃ§Ã£o do Ambiente:
Crie o ficheiro de ambiente a partir do molde:

cp .env.example .env

Configure a Base de Dados:
Abra o ficheiro .env que acabou de ser criado e preencha a variÃ¡vel DATABASE_URL com a URL de conexÃ£o do seu banco de dados PostgreSQL. Para testes locais, use a URL de conexÃ£o externa.

3. ExecuÃ§Ã£o:
a. Migrar dados para o PostgreSQL:
Este comando lÃª os dados brutos do CSV e os carrega na sua base de dados PostgreSQL. Execute apenas uma vez.

poetry run python scripts/migrate_to_postgres.py

b. Treinar o modelo:
Execute o pipeline completo para processar os dados e treinar o modelo de produÃ§Ã£o.

poetry run python src/attrition/main.py run-pipeline

c. Visualizar anÃ¡lises:

Power BI: Abra reports/dashboard.pbix e conecte-o Ã  sua base de dados PostgreSQL.

Streamlit (com prediÃ§Ã£o em tempo real):

poetry run streamlit run app/main_app.py

d. Usar a API localmente (Opcional):

Inicie a API:

poetry run uvicorn api.main:app --reload

Acesse a documentaÃ§Ã£o em http://127.0.0.1:8000/docs.

ğŸ”— Pipeline de Machine Learning
PrÃ©-processamento: Limpeza, transformaÃ§Ãµes logarÃ­tmicas.
Engenharia de Features: VariÃ¡veis derivadas, One-Hot Encoding.
Balanceamento: SMOTEENN.
OtimizaÃ§Ã£o: Optuna.
Modelagem: XGBoost.
Explicabilidade: SHAP.
AvaliaÃ§Ã£o: F1, Recall, Precision, AUC.

ğŸ“Š Resultados do Modelo (ProduÃ§Ã£o)

| Modelo              | Precision (Yes) | Recall (Yes) | F1-Score (Yes) | AUC  |
|---------------------|-----------------|--------------|----------------|------|
| Logistic Regression | 0.70            | 0.34         | 0.46           | -    |
| **XGBoost (Prod)**  | 0.54            | 0.66         | 0.60           | 0.87 |
| LightGBM            | 0.65            | 0.28         | 0.39           | 0.83 |

Recall de 66%: Detecta 2 em cada 3 saÃ­das.
AUC 0.87: Excelente separaÃ§Ã£o entre classes.
Foco em maximizar recall, dado o alto custo de perder talentos.

ğŸ“¦ Dataset
Fonte: IBM HR Analytics (Kaggle)
1.470 registros
35 features
Target: Attrition (Yes/No)

ConsideraÃ§Ãµes Ã‰ticas
Este modelo nÃ£o toma decisÃµes nem classifica funcionÃ¡rios. Ele apenas identifica padrÃµes relacionados Ã  intenÃ§Ã£o de saÃ­da e apresenta insights. Cabe exclusivamente ao RH interpretar e agir.

Para garantir que os insights sejam Ãºteis e Ã©ticos, o dashboard tÃ¡tico foi refinado para exibir apenas fatores de risco que sÃ£o diretamente influenciÃ¡veis pela gestÃ£o de RH, omitindo caracterÃ­sticas puramente pessoais.

O risco nÃ£o estÃ¡ no modelo, mas na inaÃ§Ã£o diante dos sinais.